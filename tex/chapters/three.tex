\chapter{The Algebra of Events}
\label{chap:algebra}

Measurements allow comparison of material values of phenomena historically
described by physical models that are resistant to noise. If two observers
measure the same phenomenon, then their recorded values must be comparable, no
matter the mechanism by which those measurements were obtained.

A car accelerates, and three different instruments respond. The speedometer needle
moves, the radar gun updates its readout, and the GPS velocity estimate changes.
These instruments rely on different physical mechanisms, different models, and
different internal clocks. Yet they all register a change in speed at roughly the
same time. This agreement, and nothing more, is what we mean by comparability.

Comparability is not a relation between instruments taken pairwise, nor is it a
statement about shared internal dynamics. It is a property of their records.
Two ledgers are comparable when there exists a third ledger to which both may be
coarsened without contradiction. In the present example, the coarse ledger
records only that the car’s speed changed, without committing to how that change
was detected or which internal transitions produced the mark.

Each instrument refines this coarse description in its own way. The speedometer
records wheel rotations filtered through mechanical linkages and damping. The
radar gun records Doppler shifts accumulated over reflected electromagnetic
pulses. The GPS receiver infers velocity from timing differences across satellite
signals and relativistic corrections. None of these refinements agree in detail,
and none need to. What matters is that each admits a projection onto the same
coarse event: the car was accelerating.

Simultaneity enters only at this level. The three instruments do not record their
updates at the same instant, nor do they agree on a precise ordering of internal
events. Mechanical compliance in bushings and bearings, signal propagation
delays, and electromagnetic reaction forces governed by Newton’s third law all
introduce temporal noise. These effects ensure that exact coincidence is neither
expected nor meaningful. Instead, simultaneity is the assertion that the recorded
refinements lie close enough in each ledger that no additional distinctions are
required to align them.

Thus, to say that the measurements are simultaneous is to say that their
respective records may be identified with the same coarse event without forcing
a contradiction. The comparison is made after the fact, by examining how far
apart the marks appear in each ledger. If that separation is bounded, the
measurements may be treated as witnessing the same occurrence. Simultaneity is
therefore not a primitive temporal notion, but a constraint on how distinct
records may be consistently related.

\section{Simultaneity}
We can now state simultaneity in operational terms. Consider three ledgers,
corresponding to a speedometer, a radar gun, and a GPS receiver. Each ledger
contains its own set of events, generated by distinct mechanisms and subject to
independent sources of temporal noise. No two ledgers agree pointwise in time,
and no global ordering is presumed. Simultaneity arises only through the ability
to relate these records without contradiction.

The first correspondence is kinematic. The GPS and radar gun ledgers align
because both encode change in distance over time. The GPS infers velocity from
changes in position relative to orbiting clocks, while the radar gun infers it
from Doppler shifts of reflected photons. Although the physical mechanisms are
entirely different, both ledgers refine a common coarse description: the car’s
velocity changed.

The second correspondence is mechanical. The speedometer ledger aligns with the
radar gun ledger because the acceleration of the car is conveyed through friction
at the tires and, depending on conditions, through gravitational interaction
with the road surface. Wheel rotations are mechanically coupled to the vehicle’s
body panels, which in turn scatter the photons measured by the radar gun. The
matching here is not abstract, but causal: the same force that accelerates the
car produces distinguishable marks in both ledgers.

The third correspondence is indirect but essential. The speedometer and GPS
ledgers may be aligned even without direct physical interaction, because the
existence of the radar gun ledger constrains both. Once the radar and GPS ledgers
are identified with a common coarse event, and the radar and speedometer ledgers
are likewise identified, the speedometer and GPS ledgers inherit comparability.
This correspondence arises not from shared mechanism, but from ledger consistency
under transitive refinement.

These three operations are sufficient. Simultaneity does not require a shared
clock, a global time parameter, or instantaneous coordination. It requires only
that each ledger admit a refinement or coarsening that identifies the same coarse
event, and that these identifications be mutually consistent. In this sense,
simultaneity is not an additional structure imposed on events, but a property of
how multiple records can be jointly reconciled.

The discussion of simultaneity implicitly assumes more than coincidence in
recorded order. To say that measurements are simultaneous is to say that they
can be compared without contradiction. This comparability does not arise from
shared mechanisms or synchronized clocks, but from the existence of a common
description to which the records may be related.

In this sense, comparability marks the transition from recorded refinement to
phenomenal structure. When two or more ledgers are comparable, there exists a
coarse description under which their respective refinements may be identified
as referring to the same occurrence. The nature of that occurrence has not yet
been specified; only its admissibility is asserted. This observation motivates
the introduction of admissible events.


\subsection{Admissible Events}

The discussion of simultaneity and comparability points to a common underlying
requirement. When multiple ledgers are said to record the same occurrence, there
must exist a description under which those records can be reconciled without
contradiction. This requirement does not assert that such a description is known
in advance, nor that it is uniquely realized. It asserts only that comparison is
possible.

We therefore introduce the notion of an \emph{admissible event}. An admissible
event is not a primitive object in time, nor a moment shared by all observers.
It is a phenomenal configuration whose existence is implied by the ability to
compare distinct records. An event is admissible if there exists at least one
coarse description under which the refinements recorded in multiple ledgers may
be identified as referring to the same occurrence.

Admissibility is a consistency condition, not a claim of observation. An
admissible event need not appear explicitly in any single ledger, and it need
not be recorded by all instruments. It exists only insofar as it can support
mutually consistent refinements. If no such description exists, the records
cannot be compared without introducing unrecorded assumptions, and no event is
admissible.

This definition deliberately avoids assigning temporal location, causal
direction, or mechanism to events. Those structures may be introduced later, but
they are not required for admissibility. At this stage, an event is nothing more
than a minimal anchor for comparison: a condition whose existence permits
distinct ledgers to be related without contradiction.

\begin{definition}[Admissible Event]
\label{def:admissible-event}
Let $p$ be a phenomenon and let $\{\Ledger_i\}_{i \in I_p}$ be the ledgers of
instruments capable of measuring $p$. An event $e$ is \emph{admissible} for $p$
if there exists at least one ledger $\Ledger_i$ and a refinement map under which
$e$ can be realized without contradiction with the recorded distinctions in
$\Ledger_i$.

Equivalently, an event is admissible if its existence is consistent with the
historical record of at least one instrument measuring the phenomenon.
\end{definition}

Admissible events therefore occupy an intermediate role between raw records and
phenomenal models. They do not arise from physical law alone, nor from individual
measurements in isolation. They arise from the requirement that multiple records
be jointly intelligible. In this sense, admissible events are not assumed by the
theory; they are forced by the practice of measurement itself.


\subsection{Correlance}

The Monty Hall problem entered popular culture not as a theorem, but as a minor
television ritual.  A contestant stands before three closed doors.  Behind one
is a prize; behind the others, goats.  The contestant selects a door.  The host,
who knows where the prize is hidden, opens one of the remaining doors to reveal
a goat, and then offers the contestant a choice: remain with the original door
or switch to the other unopened one.

The puzzle is famous because the correct strategy appears to violate common
sense.  Switching doors improves the chance of winning, even though only one
door has been eliminated.  Decades of explanations have framed this result as a
lesson in conditional probability, and the problem is now a staple of Bayesian
reasoning.

For our purposes, the interest of the Monty Hall problem lies elsewhere.  The
essential feature is not the numerical value of any probability, but the way
distinct records of the same game are permitted to be combined.

The contestant's notebook records only what is directly observed: the initial
choice, the door opened by the host, and the symbol revealed.  The host's
notebook records additional structure: the placement of the prize and the rule
governing which door may be opened.  These two ledgers are not identical, nor do
they contain the same information.  Nevertheless, in the standard formulation
of the game, they are understood to describe the same trial.

This shared understanding is not automatic.  It relies on the existence of at
least one way to interpret both records as refinements of a single underlying
occurrence.  The contestant may not know where the prize is, but the host's
action is constrained by that hidden fact.  Because the host is forbidden from
opening the prize door, the observation that a goat is revealed is not neutral.
It restricts which phenomenal configurations remain admissible.

Now consider a slight alteration of the story.  Suppose the host follows no such
rule and opens a door at random among those not chosen by the contestant.  The
contestant's recorded observations may be identical: a goat is revealed and a
switch is offered.  Yet the meaning of that observation has changed.  The same
ledger entry no longer carries the same interpretive force, because it is no
longer guaranteed to be compatible with the host's record under a single
phenomenal description.

Nothing probabilistic has changed.  What has changed is whether the two ledgers
can be jointly embedded into a common event without contradiction.  In the
first case they can; in the second they cannot without introducing an
unrecorded assumption about the host's behavior.

This distinction motivates the notion of correlance.  Two records may be
individually admissible and yet fail to describe the same phenomenon.  Joint
inference is permitted only when a shared admissible event exists that is
consistent with both ledgers.  The Monty Hall problem is not, at its core, a
paradox of probability.  It is a demonstration that interpretation depends on
the structure of admissible events.

We now formalize the notion of correlance.
Correlance expresses when two records may be understood as referring to the same
phenomenal occurrence. It does not assert a causal mechanism, a temporal order,
or a shared instrument. It asserts only that the records can be reconciled
without contradiction.

Two ledgers are said to be \emph{correlant} if there exists at least one
admissible event for the phenomenon under study that is consistent with both
records. In this case, each ledger may be viewed as a refinement of a common
phenomenal configuration, even if the refinements differ in detail, ordering, or
resolution. Correlance therefore depends on the existence of a shared admissible
event, not on agreement between the ledgers themselves.

Conversely, two ledgers are \emph{uncorrelant} if no admissible event exists with
which both records are consistent. In this case, no coarsening can reconcile the
records without introducing unrecorded assumptions. The absence of correlance
does not indicate error or contradiction within either ledger; it indicates only
that the records do not participate in a common phenomenal description.

Correlance is a relational property of records, not a property of events. It may
hold between ledgers that differ widely in mechanism, precision, and temporal
structure. It may also fail even when records are individually consistent and
well formed. In this sense, correlance marks the boundary between joint
interpretability and independent description.

This definition deliberately avoids probabilistic language. Correlance does not
measure the strength of association, nor does it quantify uncertainty. It is a
binary condition expressing whether joint refinement is admissible at all.
Quantitative notions of dependence, when they appear, will be introduced later
as derived constructs built atop this minimal foundation.

\begin{definition}[Correlant Records]
\label{def:correlant}
Let $p$ be a phenomenon and let $\Ledger_i$ and $\Ledger_j$ be two ledgers
measuring $p$. The ledgers are said to be \emph{correlant} if there exists an
admissible event $e$ for $p$ such that both $\Ledger_i$ and $\Ledger_j$ admit
refinements consistent with $e$.
\end{definition}

\begin{definition}[Uncorrelant Records]
\label{def:uncorrelant}
Let $p$ be a phenomenon and let $\Ledger_i$ and $\Ledger_j$ be two ledgers
measuring $p$. The ledgers are said to be \emph{uncorrelant} if no admissible
event exists for $p$ with which both records are consistent.
\end{definition}
The definitions above mark the point at which the framework becomes predictive.
Correlance and uncorrelance do not describe physical mechanisms; they delimit the
domain in which joint interpretation is even meaningful.  Once this boundary is
fixed, entire classes of inference are either licensed or forbidden without
appeal to dynamics or probability.

In particular, uncorrelance identifies situations in which no refinement of the
experimental ledger can supply a shared anchor for comparison.  In such cases,
any attempt to complete the description by introducing intermediate structure is
a representational choice rather than an observational consequence.  The ledger
alone cannot decide between competing completions, because no admissible event
exists to mediate them.

This observation has immediate mathematical consequences.  When refinement
cannot be uniquely anchored to admissible events, the question of whether
intermediate distinctions exist becomes undecidable within the ledger framework
itself.  The resulting ambiguity is not a defect of logic, but a reflection of
the fact that multiple completions are compatible with the same finite record.

The first phenomenon we examine under this lens is the status of the continuum
itself.


\begin{phenom}{The Hall--Einstein--Podolsky--Rosen Effect}
\label{ph:hall-epr}

\PhStatement
Inferences drawn from one experimental ledger about another are admissible only
when the two ledgers are correlant.  When correlance fails, Bayesian
conditioning and causal explanation alike introduce unrecorded structure.  The
Monty Hall problem and EPR--type correlation experiments exhibit the same
failure mode at different scales.

\PhOrigin
The Monty Hall problem entered the public consciousness as a paradox of
probability, while the Einstein--Podolsky--Rosen argument challenged the
completeness of quantum mechanics.  Though historically distinct, both expose a
common assumption: that distinct records may always be embedded into a single
underlying event.  The Hall--EPR Effect identifies the breakdown of this
assumption as structural rather than probabilistic or dynamical.

\PhObservation
In the classical Monty Hall game, the contestant's ledger records only observable
actions: an initial choice and the opening of a door revealing a goat.  The
host's ledger records additional constraints, including the placement of the
prize and the rule forbidding the opening of the prize door.  Because these
constraints exist, there is at least one admissible event consistent with both
ledgers.  The records are correlant, and joint inference is meaningful.

If the host's constraint is removed, the contestant's ledger may remain
unchanged, yet no admissible event exists that is consistent with both ledgers
under the standard interpretation of the game.  The records become uncorrelant,
and the same observation loses its inferential force.

EPR--type experiments realize the same structure at the microscopic scale.
Spatially separated detectors record locally consistent outcomes, each producing
a well-formed ledger.  However, no single admissible event exists that can be
decomposed into independent local components while preserving the observed
correlations under classical assumptions.  The ledgers are locally admissible
but globally uncorrelant.

In both cases, the apparent paradox arises when one attempts to condition one
ledger on another without first establishing correlance.  The inference fails
not because the records are contradictory, but because no shared admissible
event exists to anchor their joint interpretation.

\PhConstraint
No extension of the experimental ledger may condition, merge, or update one
record using another unless the two are correlant.  Any inference that presumes
a shared event in the absence of correlance introduces unrecorded structure and
violates admissibility.

\PhConsequence
The Hall--EPR Effect reframes both classical and quantum paradoxes as failures of
correlance rather than failures of probability, locality, or realism.  Bayesian
prediction remains valid, but only within domains where a shared admissible event
exists.  When correlance fails, numerical conditioning and causal explanation
remain algebraically consistent but physically meaningless.

This effect motivates the search for representational structures that restore
correlance without contradiction.  Later constructions---including geometric
identification in ER=EPR---may be understood as attempts to repair correlance at
the level of admissible events, rather than as explanations of causal influence.
\end{phenom}

An important asymmetry follows immediately from the definition.  Correlance is
stable under refinement.  If two ledgers are correlant at some stage of
observation, then any admissible extension of either ledger preserves that
correlance.  Once a shared admissible event exists, no further refinement may
eliminate it without contradicting the recorded distinctions.

By contrast, uncorrelance is provisional.  Two ledgers may fail to share an
admissible event at an early stage simply because insufficient structure has
been recorded.  Subsequent refinement may introduce new admissible events that
render the ledgers correlant.  Uncorrelant records may therefore become
correlant, but the reverse transition is forbidden.

This monotonicity reflects the irreversibility of measurement.  Refinement can
exclude incompatible descriptions, but it cannot revoke the existence of an
admissible event once established.


\section{The Experimental State}

The experimental ledger records a sequence of distinguishable events in the
order they are observed.  The experimental state, by contrast, summarizes the
informational content of that record without regard to the particular sequence
by which it was obtained.  Different sequences of refinement may therefore
correspond to the same state whenever their distinctions commute.  Physical
description concerns the state, not the order of discovery.

The experimental state is defined as the collection of instruments whose ledgers
are mutually correlant at a given stage of refinement.  It is not a physical
configuration of the system, nor a hypothesis about unobserved structure, but
the maximal description that can be maintained without contradiction under the
current record.  The state persists so long as no admissible event distinguishes
between alternative refinements.

In practice, the experimental state is often far coarser than the underlying
physical processes that generate it.  Instruments do not record all possible
distinctions, but only those they are designed to resolve.  Many distinct
microscopic configurations may therefore project onto the same experimental
state.  This coarsening is not a defect, but the mechanism by which coherent
comparison between instruments becomes possible.

A familiar illustration is provided by the use of a colored indicator in a
titration experiment.  At the microscopic level, quantities such as the relative
populations of $\mathrm{H^+}$ and $\mathrm{OH^-}$ vary continuously as titrant is
added.  A sufficiently refined ledger could, in principle, record these changes
directly.  The indicator, however, reports only a coarse symbol, typically a
binary color change.  Many distinct internal configurations are therefore
rendered indistinguishable and correspond to the same experimental state.

As titration proceeds, successive drops may alter the internal composition of
the solution without producing any new recorded distinction.  During this
interval, the experimental state remains unchanged, even though refinement
continues at the level of the ledger.  The absence of a color change reflects
ledger silence rather than physical stasis.  Only when a tolerance threshold is
crossed does an admissible event occur and the state transition to a new value.

The experimental state thus functions as a coherent description rather than a
complete history.  It records exactly those distinctions that have survived
refinement and comparison, and no more.  In subsequent sections, admissible
events will be treated as operators acting on this state, and the accumulation
of such actions will give rise to the algebraic structure that governs causal
ordering.

\subsection{Events as Operators on State}

An admissible event acts on the experimental state by restricting the set of
continuations consistent with the ledger.  This action is not a refinement of
the ledger itself, but a transformation of the state it represents.  Each
admissible event therefore induces a well-defined operator on the space of
experimental states.

This operator does not generate motion or dynamics.  It encodes exclusion.
When an event is recorded, all histories incompatible with that record are
discarded.  The resulting state is the maximal description that remains
consistent with the enlarged ledger.  In this sense, events act by subtraction
rather than construction.

The distinction between refinement and state evolution is essential.  A
refinement may add a new record without altering the experimental state if no
new distinction is resolved at the level of the instruments under comparison.
In such cases, the corresponding operator acts trivially on the state, even
though the ledger has grown.

The titration experiment again provides a concrete illustration.  Each drop of
titrant is recorded as an event in the ledger.  As long as the indicator color
remains unchanged, these events induce operators that act as the identity on the
experimental state.  The internal composition of the solution evolves, but the
state of the experiment does not.  Only when a drop produces a color change does
the associated operator map the state to a distinct successor.

This separation clarifies the role of silence.  Ledger silence does not imply
the absence of events, but the absence of state transitions.  Operators may be
applied repeatedly without effect until a tolerance condition is met and a new
admissible distinction is recorded.

In the sections that follow, we examine how such operators compose.  Whether
their order matters depends not on the events themselves, but on their
correlance relative to the state on which they act.  This leads naturally to a
state-relative notion of commutation and, ultimately, to the accumulated
structure encoded by the causal universe tensor.

\subsection{Commutation as a State-Relative Property}

Whether two event operators commute is determined by their correlance with
respect to the state on which they act.  Uncorrelant refinements commute, while
correlant refinements need not.  Commutation is therefore a relational property,
not an intrinsic one.

When two admissible events are uncorrelant relative to a given experimental
state, no admissible event exists that anchors a causal ordering between them.
The state cannot distinguish the order in which they are applied, and the
corresponding operators commute.  In such cases, ordering carries no
experimental content, even though refinement continues at the level of the
ledger.

This situation is common in practice.  In the titration experiment, successive
drops of titrant that do not alter the recorded indication are uncorrelant with
respect to the experimental state.  Their order of application is immaterial:
the resulting state is unchanged regardless of ordering.  The operators commute
because the state aliases their effects.

Correlance alters this behavior.  When two events share an admissible anchor,
their relative ordering may constrain future refinements.  The experimental
state may distinguish between different orderings, and the corresponding
operators need not commute.  Noncommutation thus reflects the presence of
potential causal structure, not a failure of algebraic regularity.

Importantly, commutation may change as the state evolves.  Operators that commute
in one state may fail to commute in another once new distinctions are recorded.
The algebra of event operators is therefore state-dependent, reflecting the
resolving power of the experimental description rather than intrinsic properties
of the events themselves.

This state-relative view of commutation will play a central role in the
construction that follows.  The accumulation of event operators records not a
total ordering of events, but a pattern of partial orders enforced by
admissibility.


















\section{Refinement of the Causal Universe Tensor}

We now present the \emph{Causal Universe Tensor}.

\begin{proposition}[The Existence of a Causal Universe Tensor]
\label{prop:universe-tensor}
\end{proposition}

Categorically, the structure underlying this result is the
naturality of a monoidal functor in the sense of
Mac~Lane~\cite{maclane1971}, with further development in
Kelly~\cite{kelly1982} and Leinster~\cite{leinster2014}.  The proof sketch
below follows this diagrammatic perspective; the fully explicit ZFC
realization appears in Appendix~\ref{app:proofs}.

\begin{proofsketch}{universe-tensor}
\end{proofsketch}

The existence of the Causal Universe Tensor gives rise to the appearance of
stability in long sequences of refinement.  Because each admissible update is
not free to evolve arbitrarily, but must remain compatible with the unique
globally coherent extension of the record, deviations cannot accumulate
without bound.  Local inconsistencies are absorbed through restriction and
embedding, producing the observable effect of bounded variation in the
measurement ledger.  This structural stability is not enforced by physical
feedback or control, but by the logical necessity of coherent refinement
itself.  This gives rise to the following informational phenomenon.

