\chapter{Calibration}
Recall the thought experiment of the parked car and the speedometer from last
chapter.  The car is loaded onto a train and transported across
the country.  The displacement is large, the duration is long, and ordinary
reasoning would readily describe the episode as one of sustained motion.  Yet
the speedometer continues to record nothing at all.  Its silence is not a
failure of detection or a lack of sensitivity.  It is a faithful expression of
its construction.  Motion that does not pass through wheel rotation is
inadmissible to this instrument and therefore invisible to its ledger.

When the car is finally driven again, the wheel completes its next rotation and
the speedometer advances by exactly one count.  The instrument does not record
how long the car was idle, does not distinguish whether the pause lasted minutes
or decades, and does not reflect the intervening transport.  Its ledger
registers only the completion of a bounded exchange.  All intervening time and
motion lie outside its refinement path and therefore outside its history.

This example establishes a central lesson carried forward from the previous
chapter.  Instruments do not record what happens in general.  They record only
what their refinement structure permits.  Silence is not ignorance about hidden
activity; it is the absence of licensed distinction.  From the perspective of
the speedometer, the transported car has no history during the interval of
stillness, regardless of what may be inferred by other means.

However, consider another device capable of measuring the phenomenon we call
speed.  A global positioning system (or GPS) device does not refine
motion through mechanical cycles.  It refines position by receiving timed
signals from distant sources and committing the result as a coordinate.  Its
ledger advances by solving a synchronization problem rather than by waiting for
a wheel rotation.  Where the speedometer is silent, the GPS may remain active.

The GPS therefore records a history that the speedometer cannot.  During the
train ride, new position fixes may be committed, each summarizing a completed
internal computation.  These entries do not contradict the silence of the
speedometer, because they belong to a different ledger governed by a different
refinement scheme.

The two instruments do not disagree.  They simply speak in nonoverlapping
alphabets.  That this fact is easy to miss is itself instructive.  Both
instruments may display values labeled in the same units, such as kilometers
per hour, yet those labels conceal fundamentally different modes of
construction.  What appears as a common numerical value is, at the level of the
ledger, a projection from distinct symbolic processes.

Agreement in units does not imply agreement in records.  It signals only that
the two ledgers admit a common coarsening under which their outputs may be
compared.  The apparent equivalence of the displayed values is therefore not a
primitive fact, but a consequence of calibration.  It is achieved by suppressing
details that belong to one refinement scheme but not the other.

The problem addressed in this chapter is not how to choose between such
instruments, nor how to privilege one account of motion over another.  It is
how records produced by distinct instruments may nevertheless be compared.
What observers agree upon is not a shared internal state or a common notion of
simultaneity, but the consistency of their recorded histories when projected to
a suitable level of description.

At that coarser level, familiar quantities emerge.  Speed is not located in the
wheel rotation count, nor in the satellite timing solution.  It appears as a
phenomenal invariant: a relation that remains stable across the union of
moments produced by both instruments when their ledgers are aligned.  Each
ledger refines this invariant differently, and neither refinement is reducible
to the other.

This reconciliation reveals the role of physical law within the framework.
Laws do not generate motion, nor do they dictate what an instrument must see.
They act as bookkeeping constraints that preserve coherence across heterogeneous
records.  The GPS does not correct the speedometer, and the speedometer does not
invalidate the GPS.  Together, they demonstrate how calibration arises from the
controlled comparison of distinct ledgers, each faithful to its own mode of
observation.

The remainder of this chapter develops the structures required for such
comparisons.  It formalizes how ledgers may be aligned, how silence in one record
may coexist with activity in another, and how calibration permits instruments
with different clocks, alphabets, and refinement paths to participate in a
common phenomenal description without contradiction.

\section{Invariant}

We begin with our preferred invariant: speed.  As we have seen, speed is not observed
directly.  It is inferred from records produced by instruments that operate by
very different mechanisms.  A mechanical speedometer counts wheel rotations.  A
radar gun infers velocity from Doppler shift.  A GPS receiver estimates
displacement over time from satellite signals.  Each produces a finite record,
and none is privileged.

Despite this diversity, these instruments are understood to be measuring the
same thing.  This is not because they report identical values, but because their
records are mutually compatible.  Each record excludes large classes of
possible motions.  A speedometer reading rules out zero velocity.  A radar
measurement rules out backward motion.  A GPS track rules out discontinuous
jumps.  What remains is a shared constraint on what the motion could have been.

That shared constraint is the invariant.  It is not a number written on a dial,
but the set of possibilities that survive all recorded restrictions.  As new
records are added, this set can only shrink.  Measurement proceeds by
elimination, not by revelation.

This immediately introduces order.  One record may be strictly more informative
than another.  A longer GPS trace refines a shorter one.  A radar average over
many pulses refines a single pulse.  A record that excludes more possibilities
is said to be a refinement of one that excludes fewer.  Refinement is therefore
a relation between records.

The collection of admissible records, ordered by refinement, forms a partial
order.  Two records are comparable only when one rules out everything the other
does.  When neither refines the other, they are simply different views of the
same underlying constraint.  When their admissible sets fail to intersect, they
cannot both be correct.

In this way, the invariant of speed is not a single value but an ordered family
of admissible descriptions.  Agreement between instruments does not mean equality
of outputs; it means the existence of a common refinement.  Disagreement is not
noise to be averaged away, but a logical incompatibility that cannot be repaired.

This ordered structure is the invariant that will matter throughout this
chapter.  It is not introduced by assumption, nor derived from continuity.
It arises directly from the way instruments restrict possibility.  The next
sections show how this order is navigated, coordinated, and ultimately realized
by devices.

\subsection{Observed Quantities}

An observed quantity is not a property of a system.  It is a record produced by
an instrument.  What distinguishes one observed quantity from another is not
what it represents, but how it restricts possibility.  An observation is a
commitment to a finite distinction, and nothing more.

We continue with the example of speed.  A speedometer reports a number derived
from wheel rotations.  A radar gun reports a value inferred from Doppler shift.
A GPS receiver reports a sequence of positions indexed by timestamps.  These
records are not interchangeable, nor are they directly comparable.  Each is an
observed quantity because each is the output of a specific instrument operating
under a specific decomposition.

What makes these records quantities at all is that they admit ordering.  One
observation may be strictly more informative than another.  A speedometer
reading averaged over ten seconds refines a single instantaneous reading.  A
GPS trajectory over a mile refines a trajectory over one hundred meters.  An
observed quantity is therefore not a point value, but an element in an ordered
collection of admissible records.

This ordering does not arise from numerical magnitude.  A larger reported speed
is not a refinement of a smaller one.  Refinement is instead determined by
exclusion: an observation refines another if it rules out every possibility
that the other rules out, and more.  Observed quantities are ordered by the
strength of their constraints, not by their reported values.

Two observed quantities need not be comparable.  A radar measurement and a GPS
track may exclude different possibilities without one strictly refining the
other.  In such cases, they represent distinct observations of the same
underlying phenomenon.  They become related only when they admit a common
refinement.  Compatibility, not equality, is the criterion for agreement.

Observed quantities are therefore inherently discrete.  Each arises from a
finite act of recording, and each admits only finitely many refinements before
new instrumentation or new observation is required.  There is no requirement
that observed quantities vary continuously, nor that they lie along a smooth
scale.  Continuity, when it appears, is an emergent feature of dense refinement,
not a primitive assumption.

This view separates observed quantities from inferred structure.  An observed
quantity does not encode motion, speed, or trajectory directly.  It encodes a
restriction on what motion could have occurred.  The role of the next sections
is to show how such restrictions are coordinated across instruments, and how
families of observed quantities give rise to stable measurement.


\section{Instrument}

An instrument is not defined by what it detects, but by what it licenses.  It
specifies which distinctions may be admitted into the ledger and which must be
suppressed to preserve coherence.  In this sense, an instrument is a rule for
facthood rather than a mechanism for discovery.

Prior to calibration, an instrument may appear to merely register signals.
After calibration, it is understood as enforcing an invariant.  The instrument
does not reveal structure; it constrains representation so that structure may be
compared across refinements.

An instrument therefore exists at the boundary between signal and record.  It
receives input from the world, but its defining action occurs before any ledger
entry is made.  During this interval, no fact yet exists.  The instrument
evaluates admissibility according to its internal rules and only then commits a
distinction.

The defining feature of an instrument is its refinement discipline.  Each
instrument carries a specification of how distinctions may be sharpened, merged,
or discarded under improved conditions.  Refinement is not an afterthought but
the core logic by which the instrument operates.

Because refinement rules differ between instruments, no instrument is universal.
Each enforces a particular notion of comparability, tied to the invariant it has
been calibrated to preserve.  Two instruments observing the same phenomenon may
produce incompatible records until calibration suppresses their incompatible
distinctions.

The instrument is therefore not reducible to its physical realization.  Springs,
photodiodes, counters, and clocks are implementations, not definitions.  What
defines the instrument is the abstract rule governing how raw signals are mapped
to admissible ledger entries.

An instrument always carries an implicit decoding map.  This map determines how
raw variation is interpreted as symbolic distinction.  Calibration fixes this
map, and any change to it constitutes a change of instrument, not merely a change
of resolution.

The role of the instrument is to ensure that refinement and projection commute.
A refinement that introduces distinctions which cannot be projected back to the
calibrated invariant is inadmissible.  In this way, the instrument enforces
recoverability as a structural constraint.

Noise, from the instrumental perspective, is not external disturbance but
internal inconsistency.  When an instrument admits distinctions that fail to
survive projection, it produces non-commuting records.  Such failures indicate
that the instrument has exceeded the limits of its calibration.

An instrument may therefore be silent without being idle.  During transport,
reconfiguration, or prediction, the instrument may produce no ledger entries at
all.  This silence is not ignorance but discipline: no admissible distinction has
yet been licensed.

The distinction between instrument and device becomes sharp at this point.  The
instrument defines admissibility; the device realizes it under repetition.  An
instrument may exist in principle without a stable device, but no device can
operate without an instrument.

Because instruments impose structure before computation, they cannot themselves
be computed.  Their rules must be declared, constructed, or calibrated.  This
non-computational character explains why representational choices precede
algorithmic ones.

The apparent continuity of many physical descriptions arises from the stability
of instrumental rules under refinement.  Continuity is not observed; it is
licensed.  The instrument allows arbitrarily fine distinctions only insofar as
they remain recoverable under projection.

Instruments therefore mediate between finite records and idealized descriptions.
They permit the use of continuous language without committing the ledger to
infinite structure.  This mediation is conditional, not absolute.

Ultimately, an instrument is the guardian of facthood.  It determines when a
distinction may be recorded, how it may be refined, and whether it may be
compared.  Without an instrument, there are signals but no facts; with an
instrument, there are facts, but only those it licenses.

\section{Device}

In the framework, the \emph{device} is the physical realization of the
instrument.  While the instrument provides the logical rules and the
Cantor--Cauchy protocol for consistency, the device is the finite, bounded entity
that must execute the work.  It marks the transition from mathematical ideal to
physical reality, where thermal limits, energy costs, and irreversible records
cannot be ignored.  The device is where the theory of measurement meets the laws
of thermodynamics and the constraints of hardware.

The device is fundamentally a \emph{finitary machine}.  Unlike the instrument,
which may be described in terms of infinite sequences or constructions, the
device is restricted by a hard limit on the number of distinctions it can
maintain.  This limit is the device's \emph{resolution}, representing the maximum
density of the ledger before the cost of adding a new entry exceeds the energy
available to the system.  In this sense, every device is a clock, and every clock
is a heat engine.

A central feature of the device is the \emph{irreversibility of the record}.  Once
a device commits a fact to the ledger, that entry cannot be undone without a
corresponding increase in the entropy of the environment.  This anchors the
system in a constructive arrow of time: the ledger only grows.  The device does
not observe a pre-existing state; it \emph{precipitates a fact} through the act of
recording, turning an indeterminate experience into a discrete, permanent, and
irreversible distinction.

The architecture of the device is defined by its internal state space, which is
strictly smaller than the phenomenal space it monitors.  This mismatch
necessitates decomposition.  Because the device is finite, it cannot capture an
invariant in its entirety; it can only record a shadow or trace of it on its
internal ledger.  This finiteness is not a flaw but the defining characteristic
that separates a physical device from a mathematical abstraction.

Within the hierarchy, the device is the site of \emph{thermal noise}.  While
noise in the gauge is a logical failure of commutation, thermal noise is a
physical failure of the device to maintain its distinctions.  As the device
operates, it generates heat, and this heat threatens to blur the very records it
creates.  To maintain a clear ledger, the device must continually export entropy,
a process that defines the physical cost of measurement.

The device realizes the Newton search and the bisection search through specific
physical mechanisms.  For iterative creation, the device acts as a transducer,
converting local physical change into a discrete increment in the ledger.  If
the device's response time is slower than the rate of change in the phenomenon,
the resulting record becomes smeared, leading to an accumulation of error in the
associated Cauchy sequence.  These mechanisms realize the instrument under finite
constraints rather than defining it.

For the bisection search, the device acts as a comparator.  It tests the
phenomenon against internal reference levels to determine the address of the
value.  This global process requires the device to maintain stable references.
If these references drift due to temperature, wear, or age, the Cantor
construction fails to align with the record, signaling that the device, rather
than the instrument, is no longer calibrated.

The encoding map is physically embedded in the device's hardware.  Whether it is
the markings on a ruler or the voltage thresholds in an analog-to-digital
converter, the map is a physical artifact.  As a result, the alphabet of the
measurement is subject to the same physical degradation as the device itself.
Calibration is therefore not merely a logical update of symbols, but a physical
realignment of hardware to ensure the map remains faithful to the ledger.

One critical aspect of the device is the \emph{sampling interval}.  Because the
device is finite, it cannot record continuously; it must pulse.  Each pulse
represents a discrete moment of interaction in which the device samples the
environment and updates the ledger.  This periodicity defines a boundary: any
phenomenon occurring faster than this pulse rate is invisible to the device,
appearing only as unresolvable background noise or aliased artifacts.

The device also defines the \emph{dynamic range} of the measurement, the ratio
between the smallest distinction it can record and the largest value it can
represent without saturation.  When a phenomenon exceeds this range, the device
clips and ledger entries lose their evidentiary meaning.  This physical
saturation is a hard boundary: beyond it, the device no longer provides an
evidence-based record, and the system must fail explicitly.

The device is also the source of \emph{latency}.  There is a finite delay between
the occurrence of a physical event and its registration in the ledger.  This
delay is a fundamental property of the device's transport mechanism.  The record
is therefore always retrospective, reinforcing the fact that measurement is an
act of history-writing rather than real-time seeing.

The coupling between the device and the phenomenon is never neutral.  Every
device exerts back-action on the system it measures.  By extracting distinctions
from the environment, the device alters that environment.  This coupling is the
physical basis of the observer effect.  If the coupling is too strong, the device
becomes part of the phenomenon it is intended to measure, destroying the
independence of the record.

The device is the ultimate judge of \emph{precision}.  While the instrument may
calculate to arbitrary levels, the device determines the actual stop bit.  The
achievable precision is limited by the signal-to-noise ratio.  High precision
requires high mass or high energy throughput, as larger signals are needed to
remain above the thermal noise floor.  In this way, the abstract geometry of the
manifold is tied directly to the physical mass-energy of the device.

Calibration of the device maps its physical responses to the logical symbols of
the instrument.  This is where the Einstein device becomes the gold standard.
By reducing operation to the simplest act, counting events, the number of
physical variables subject to drift is minimized.  A device that counts pulses
is more stable than one that measures analog voltages, which is why the count
serves as the primary primitive of the theory.

In summary, the device is the finite anchor of the theory.  It is the machine
that turns energy into information and experience into a ledger.  Without the
device, the theory of measurement remains mathematics alone; with the device, it
becomes a physical law.  The limits of the device are the limits of the theory,
and its failures, whether through noise, saturation, or drift, define the
boundaries of knowledge.

\section{Decomposition}

Decomposition is the stage at which the unity of the record is intentionally
broken.  Whereas previous sections concerned the creation, implementation, and
stability of ledger entries, decomposition addresses the asymmetry between the
act of measurement and the act of recovery.  It is here that inversion first
appears as a structural problem rather than a physical error.

A measurement may be understood as a projection from a phenomenal invariant to a
discrete ledger entry.  Decomposition is the attempt to map such an entry back
into the instrument's alphabet.  This operation is naturally described as an
inverse.  However, because projection suppresses distinctions, this inverse
cannot in general exist as an identity.

The finiteness of the device and the constraints imposed by calibration ensure
that information is lost during projection.  Any attempt at recovery must
therefore contend with this loss.  The appropriate notion of inversion is not a
true inverse, but a pseudoinverse that recovers only those distinctions licensed
by the instrument.

Decomposition introduces the principle of \emph{inversion as non-commutative
operation}.  Even when two refinement procedures yield identical ledger entries,
the order in which their inverses are applied matters.  In general, the inverse
of a composition is not the composition of inverses in the opposite order.

This non-commutativity is not an algebraic artifact but a consequence of finite
evidence.  Every decomposition corresponds to a path through the instrument's
refinement structure.  Different paths leave different residues, even when they
terminate at the same ledger symbol.

In a Newton-style refinement, the path of decomposition follows local directional
steps.  In a bisection-style refinement, decomposition retraces the elimination
of global alternatives.  Although both procedures may certify the same value,
their inversions traverse distinct regions of the device's state space.

The phrase ``even if the results agree'' is therefore essential.  Agreement of
symbols does not imply equivalence of operators.  Inversion is not a purely
formal reversal, but a constrained retracing of admissible transitions through
an irreversible machine.

Because the device is finite and thermodynamically irreversible, inversion
cannot restore the original state.  Each attempt at recovery leaves a remainder.
Identity is not given but achieved, and only approximately.  In this framework,
the identity operator is a calibrated limit, not a primitive.

This non-commutative gap is the first appearance of order-dependence in the
theory.  The order in which evidence is recovered matters because evidence
itself is history-dependent.  In a finite system, histories cannot be reordered
without changing their effect.

The emergence of geometric structure is grounded in this failure of commutation.
If all decompositions commuted, measurement would be trivial and structure would
collapse to a flat ordering.  Non-commutation introduces curvature, understood
not as a property of a background space, but as a property of ledger operations.

Decomposition also clarifies the role of gauge threads.  Transformations that
commute with projection belong to the same gauge thread.  Transformations that
fail to commute represent genuine distinctions in the phenomenal invariant.
Inversion is the first operation capable of distinguishing these cases.

Within the Cantor--Cauchy instrument, decomposition forces both refinement paths
to run backward.  Inverting a Cauchy sequence retraces local commitments.
Inverting a Cantor construction retraces eliminated alternatives.  Their failure
to commute demonstrates that creation and addressing are logically distinct
operations that meet only under calibration.

The cost of inversion is therefore real.  Undoing a measurement is not free.
It requires work, incurs error, and leaves trace.  Any theory that assumes
symmetry between measurement and recovery ignores the finitary nature of
devices.

Decomposition prepares the ground for generalized recovery operators.  Because
true inverses are unavailable, recovery must be defined relative to projection.
This necessity leads naturally to the introduction of pseudoinverses and
orthogonal projectors as the only operators compatible with calibration.

In this sense, decomposition serves as the bridge to the next chapter.  By
establishing inversion as non-commutative, it justifies why invariants can only
be approximated through sequences of constrained operations rather than solved
for directly.

Inversion is thus the watershed moment of the theory.  It is where the single
invariant is viewed through multiple, non-compatible decompositions.  From this
point onward, measurement is irreducibly dynamic, path-dependent, and
structurally incomplete.

\begin{coda}{Representational Noise}
\end{coda}

